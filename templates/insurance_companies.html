import openai
from pinecone import Pinecone, ServerlessSpec
from langchain.text_splitter import RecursiveCharacterTextSplitter  # Correct import
from langchain.vectorstores import Pinecone as LangChainPinecone
from langchain.embeddings import OpenAIEmbeddings
import os

# OpenAI and Pinecone API Keys
openai.api_key = "your-openai-api-key"

# Initialize Pinecone
pc = Pinecone(
    api_key="your-pinecone-api-key",
    serverless_spec=ServerlessSpec(
        cloud="aws",
        region="your-pinecone-region"  # Example: "us-west-2"
    )
)

# Ensure index exists or create it
index_name = "insurance-help"
if index_name not in [index.name for index in pc.list_indexes().names()]:
    pc.create_index(
        name=index_name,
        dimension=1536,  # Adjust dimension based on embeddings
        metric="cosine"
    )

index = pc.index(index_name)

# Embedding model
embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")

# Function to retrieve relevant documents from Pinecone
def retrieve_documents(query, top_k=5):
    query_embedding = embeddings.embed_query(query)
    results = index.query(query_embedding, top_k=top_k, include_metadata=True)
    return [result['metadata']['text'] for result in results['matches']]

# Function to generate response
def generate_response(query, retrieved_docs):
    context = "\n\n".join(retrieved_docs)
    system_prompt = (
        "You are a helpful insurance assistant. Use the following context to answer questions clearly and concisely.\n\n"
        f"Context:\n{context}\n\n"
        "If the context doesn't answer the question, say 'I need more information to assist you.'"
    )
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": query},
        ]
    )
    return response['choices'][0]['message']['content']

# Chatbot function
def chatbot(query):
    # Retrieve relevant documents
    retrieved_docs = retrieve_documents(query)
    if not retrieved_docs:
        return "I'm sorry, I couldn't find relevant information to assist you."
    
    # Generate response
    response = generate_response(query, retrieved_docs)
    return response

# Example usage
if __name__ == "__main__":
    user_query = input("How can I help you with your insurance today? ")
    response = chatbot(user_query)
    print(response)
